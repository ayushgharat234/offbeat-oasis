{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c83c03f3-1c07-4568-bffd-ecc61425321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c041a8af-76d8-4979-808e-1aa6683e5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = pd.read_csv(\"C:/Users/Gharat/Downloads/recommendation-engine/offbeat-oasis/data/final/locations.csv\")\n",
    "trips_df = pd.read_csv(\"C:/Users/Gharat/Downloads/recommendation-engine/offbeat-oasis/data/final/trips.csv\")\n",
    "users_df = pd.read_csv(\"C:/Users/Gharat/Downloads/recommendation-engine/offbeat-oasis/data/final/users.csv\")\n",
    "reviews_df = pd.read_csv(\"C:/Users/Gharat/Downloads/recommendation-engine/offbeat-oasis/data/final/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aebd5181-f543-43a7-8d40-4bd9d383c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def prepare_location_features(locations_df):\n",
    "    \"\"\"\n",
    "    Combine text features into one column and apply TF-IDF vectorization.\n",
    "    \"\"\"\n",
    "    locations_df['combined_features'] = (\n",
    "        locations_df['category'].fillna('') + ' ' +\n",
    "        locations_df['state'].fillna('') + ' ' +\n",
    "        locations_df['activities'].fillna('') + ' ' +\n",
    "        locations_df['places'].fillna('')\n",
    "    )\n",
    "\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(locations_df['combined_features'])\n",
    "\n",
    "    return tfidf_matrix, tfidf\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def create_user_preference_vector(travel_category, preferred_state, tfidf):\n",
    "    \"\"\"\n",
    "    Convert user preferences into the same TF-IDF space as the locations.\n",
    "    \"\"\"\n",
    "    user_text = f\"{travel_category} {preferred_state}\"\n",
    "    user_vector = tfidf.transform([user_text])\n",
    "    return user_vector\n",
    "\n",
    "def get_content_based_recommendations(user_vector, tfidf_matrix, locations_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity and return top N location recommendations.\n",
    "    \"\"\"\n",
    "    similarity_scores = cosine_similarity(user_vector, tfidf_matrix).flatten()\n",
    "    locations_df['content_score'] = similarity_scores\n",
    "\n",
    "    top_locations = locations_df.sort_values(by='content_score', ascending=False).head(top_n)\n",
    "    return top_locations[['location_id', 'location_name', 'content_score']]\n",
    "\n",
    "\n",
    "def create_user_location_matrix(reviews_df):\n",
    "    \"\"\"\n",
    "    Pivot reviews into a user-location interaction matrix.\n",
    "    \"\"\"\n",
    "    interaction_matrix = reviews_df.pivot_table(\n",
    "        index='user_id',\n",
    "        columns='location_id',\n",
    "        values='rating'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    return interaction_matrix\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_similar_users(interaction_matrix, target_user_id, k=5):\n",
    "    \"\"\"\n",
    "    Find top-K similar users to the given user_id.\n",
    "    \"\"\"\n",
    "    if target_user_id not in interaction_matrix.index:\n",
    "        return None  # Handle cold-start later\n",
    "\n",
    "    user_vector = interaction_matrix.loc[[target_user_id]]\n",
    "    similarity_matrix = cosine_similarity(user_vector, interaction_matrix)[0]\n",
    "    \n",
    "    similarity_series = pd.Series(similarity_matrix, index=interaction_matrix.index)\n",
    "    similarity_series = similarity_series.drop(target_user_id).sort_values(ascending=False).head(k)\n",
    "\n",
    "    return similarity_series\n",
    "\n",
    "def predict_ratings_for_user(interaction_matrix, similar_users, target_user_id):\n",
    "    \"\"\"\n",
    "    Predict ratings for all locations not rated by the target user using neighbors.\n",
    "    \"\"\"\n",
    "    if similar_users is None:\n",
    "        return pd.Series()  # Cold-start\n",
    "\n",
    "    neighbors_matrix = interaction_matrix.loc[similar_users.index]\n",
    "    user_ratings = interaction_matrix.loc[target_user_id]\n",
    "\n",
    "    weighted_ratings = neighbors_matrix.T.dot(similar_users)\n",
    "    normalization = similar_users.sum()\n",
    "\n",
    "    prediction_scores = weighted_ratings / normalization\n",
    "    unseen_locations = user_ratings[user_ratings == 0].index\n",
    "\n",
    "    return prediction_scores[unseen_locations].sort_values(ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939a7fc6-4e79-4dc9-9a7c-2e9fe2cc2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Similarity calculation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Optional: To suppress SettingWithCopyWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c807e7-2d26-4e20-9ef3-ef6feb655171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_location_cost(reviews_df, trips_df):\n",
    "    \"\"\"\n",
    "    Estimate the cost of each location by averaging the trip cost of users who visited it.\n",
    "    \"\"\"\n",
    "    merged_df = reviews_df.merge(trips_df, on='user_id', how='left')\n",
    "    location_costs = merged_df.groupby('location_id')['cost'].mean().reset_index()\n",
    "    location_costs.columns = ['location_id', 'estimated_cost']\n",
    "    return location_costs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a85b2cd-c2c0-4aa8-a799-ebb760cb75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_budget_filter(location_df, location_costs, trip_budget):\n",
    "    \"\"\"\n",
    "    Merge estimated costs with location recommendations and filter by budget.\n",
    "    \"\"\"\n",
    "    merged = location_df.merge(location_costs, on='location_id', how='left')\n",
    "    filtered = merged[merged['estimated_cost'] <= trip_budget]\n",
    "    return filtered.sort_values(by='estimated_cost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c54570e5-4679-4ee2-a2e7-c1e9cb54195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(series):\n",
    "    \"\"\"\n",
    "    Normalize a pandas Series between 0 and 1.\n",
    "    \"\"\"\n",
    "    return (series - series.min()) / (series.max() - series.min() + 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcdc1892-5e37-4fbc-84bf-8088a6ac164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scores(content_df, collab_scores, weight_content=0.5, weight_collab=0.5):\n",
    "    \"\"\"\n",
    "    Combine normalized content-based and collaborative filtering scores.\n",
    "    \"\"\"\n",
    "    content_df = content_df.copy()\n",
    "    content_df['normalized_content'] = normalize_scores(content_df['content_score'])\n",
    "\n",
    "    collab_df = collab_scores.reset_index()\n",
    "    collab_df.columns = ['location_id', 'collab_score']\n",
    "    collab_df['normalized_collab'] = normalize_scores(collab_df['collab_score'])\n",
    "\n",
    "    merged = content_df.merge(collab_df, on='location_id', how='left')\n",
    "    merged['normalized_collab'] = merged['normalized_collab'].fillna(0)\n",
    "\n",
    "    merged['hybrid_score'] = (\n",
    "        weight_content * merged['normalized_content'] +\n",
    "        weight_collab * merged['normalized_collab']\n",
    "    )\n",
    "\n",
    "    return merged.sort_values(by='hybrid_score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a5cfa5-55ad-47dc-b40b-e6bb0c6ef951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            location_name  hybrid_score  estimated_cost\n",
      "32     Kanha National Park'S Buffer Zones      0.600000       17266.218\n",
      "9                                  Orchha      0.570310       11500.000\n",
      "21                                  Kalpa      0.432409       14500.000\n",
      "16                         Tirthan Valley      0.400420       13405.845\n",
      "24                                 Jawhar      0.363935       15150.500\n",
      "18                                 Shojha      0.350902       14165.170\n",
      "26                            Polo Forest      0.323216       15600.000\n",
      "23  Athirappilly And Vazhachal Waterfalls      0.299470       15126.440\n",
      "28                               Thenmala      0.248964       16050.750\n",
      "30                           Araku Valley      0.211222       16200.000\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "travel_category = \"Nature\"\n",
    "preferred_state = \"Himachal Pradesh\"\n",
    "trip_budget = 40000\n",
    "target_user_id = 101  # Assume this user exists in the dataset\n",
    "\n",
    "# STEP 1: Content-Based Filtering\n",
    "tfidf_matrix, tfidf = prepare_location_features(locations_df)\n",
    "user_vector = create_user_preference_vector(travel_category, preferred_state, tfidf)\n",
    "content_recs = get_content_based_recommendations(user_vector, tfidf_matrix, locations_df, top_n=50)\n",
    "\n",
    "# STEP 2: Collaborative Filtering\n",
    "interaction_matrix = create_user_location_matrix(reviews_df)\n",
    "similar_users = get_top_k_similar_users(interaction_matrix, target_user_id, k=5)\n",
    "collab_scores = predict_ratings_for_user(interaction_matrix, similar_users, target_user_id)\n",
    "\n",
    "# STEP 3: Budget Filtering\n",
    "location_costs = estimate_location_cost(reviews_df, trips_df)\n",
    "filtered_content = apply_budget_filter(content_recs, location_costs, trip_budget)\n",
    "\n",
    "# STEP 4: Combine Scores\n",
    "final_recommendations = combine_scores(filtered_content, collab_scores, weight_content=0.6, weight_collab=0.4)\n",
    "\n",
    "# Show Top N Results\n",
    "print(final_recommendations[['location_name', 'hybrid_score', 'estimated_cost']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d7e7c4-8033-4b43-bca5-9b3d9692a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_split_reviews(reviews_df, test_size=0.2, random_state=42):\n",
    "    return train_test_split(reviews_df, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def evaluate_rating_predictions(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return rmse, mae\n",
    "\n",
    "def evaluate_rating_predictions(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return rmse, mae\n",
    "\n",
    "def precision_recall_at_k(actual, predicted, k=10):\n",
    "    actual_set = set(actual[:k])\n",
    "    predicted_set = set(predicted[:k])\n",
    "    intersection = actual_set & predicted_set\n",
    "\n",
    "    precision = len(intersection) / float(k)\n",
    "    recall = len(intersection) / float(len(actual)) if actual else 0.0\n",
    "    return precision, recall\n",
    "\n",
    "def dcg_at_k(relevance_scores, k):\n",
    "    relevance_scores = np.asarray(relevance_scores)[:k]\n",
    "    if relevance_scores.size:\n",
    "        return np.sum(relevance_scores / np.log2(np.arange(2, relevance_scores.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(actual, predicted, k=10):\n",
    "    relevance = [1 if item in actual else 0 for item in predicted[:k]]\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    dcg = dcg_at_k(relevance, k)\n",
    "    idcg = dcg_at_k(ideal_relevance, k)\n",
    "    return dcg / idcg if idcg > 0 else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed397264-eb52-4c0b-b707-f22f8ea7a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_topk(ground_truth, predicted_top_k, k=10):\n",
    "    precisions, recalls, ndcgs = [], [], []\n",
    "\n",
    "    for user_id in ground_truth:\n",
    "        actual = ground_truth[user_id]\n",
    "        predicted = predicted_top_k.get(user_id, [])\n",
    "\n",
    "        precision, recall = precision_recall_at_k(actual, predicted, k)\n",
    "        ndcg = ndcg_at_k(actual, predicted, k)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return {\n",
    "        \"Precision@K\": np.mean(precisions),\n",
    "        \"Recall@K\": np.mean(recalls),\n",
    "        \"NDCG@K\": np.mean(ndcgs)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5beb4939-24a7-4888-9695-4f1bfdafae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_reviews, test_reviews = train_test_split(reviews_df, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def compute_rmse_mae(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return rmse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b16aae2-b050-4c1b-ad65-efc9f7b0d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_locations(travel_category, preferred_state, trip_budget, top_k=10, user_id=None): \n",
    "        \"\"\" Generate top-k hybrid travel location recommendations.\n",
    "        Parameters:\n",
    "        travel_category (str): e.g., 'Adventure', 'Nature'\n",
    "        preferred_state (str): e.g., 'Himachal Pradesh'\n",
    "        trip_budget (float): Maximum trip budget\n",
    "        top_k (int): Number of locations to recommend\n",
    "        user_id (int): ID of the target user (optional, used for collaborative filtering)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Top recommended locations with hybrid scores\n",
    "    \"\"\"\n",
    "    \n",
    "        # Step 1: Content-Based Filtering\n",
    "        tfidf_matrix, tfidf = prepare_location_features(locations_df)\n",
    "        user_vector = create_user_preference_vector(travel_category, preferred_state, tfidf)\n",
    "        content_recs = get_content_based_recommendations(user_vector, tfidf_matrix, locations_df, top_n=50)\n",
    "        \n",
    "        # Step 2: Collaborative Filtering\n",
    "        interaction_matrix = create_user_location_matrix(reviews_df)\n",
    "        \n",
    "        if user_id is not None and user_id in interaction_matrix.index:\n",
    "            similar_users = get_top_k_similar_users(interaction_matrix, user_id, k=5)\n",
    "            collab_scores = predict_ratings_for_user(interaction_matrix, similar_users, user_id)\n",
    "        else:\n",
    "            collab_scores = pd.DataFrame(columns=[\"location_id\", \"predicted_rating\"])\n",
    "        \n",
    "        # Step 3: Budget Filtering\n",
    "        location_costs = estimate_location_cost(reviews_df, trips_df)\n",
    "        filtered_content = apply_budget_filter(content_recs, location_costs, trip_budget)\n",
    "        \n",
    "        # Step 4: Combine content + collaborative scores\n",
    "        final_recommendations = combine_scores(filtered_content, collab_scores, weight_content=0.6, weight_collab=0.4)\n",
    "        \n",
    "        # Return sorted top-K recommendations\n",
    "        return final_recommendations.sort_values(\"hybrid_score\", ascending=False).head(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b7fc5a2-971b-4183-a3fb-7b7d0dff2cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          location_name  hybrid_score  estimated_cost\n",
      "2                            Meghamalai      0.600000       7987.6500\n",
      "3                          Malshej Ghat      0.488734       9345.6700\n",
      "22                               Amboli      0.460615      14769.3100\n",
      "8        Pangong Tso West Bank Villages      0.400000      11423.0225\n",
      "0                         Poovar Island      0.000000       5611.6900\n",
      "4                            Mokokchung      0.000000       9345.6700\n",
      "5                               Kachchh      0.000000       9861.9750\n",
      "6   Coorg'S Offbeat Trails And Villages      0.000000       9994.2000\n",
      "7                           Ziro Valley      0.000000      10500.5000\n",
      "9          Chopta-Tungnath-Chandrashila      0.000000      11439.3300\n"
     ]
    }
   ],
   "source": [
    "recommended_locations = recommend_locations(travel_category=\"Adventure\", preferred_state=\"Maharashtra\", trip_budget=15000, top_k=10, user_id=10) \n",
    "\n",
    "print(recommended_locations[[\"location_name\", \"hybrid_score\", \"estimated_cost\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe055dfe-897b-40d8-a35c-f1d0c9249d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "test_user_ids = reviews_df[\"user_id\"].unique()[:20] # Adjust the slice as needed\n",
    "\n",
    "ground_truth = defaultdict(list) \n",
    "predicted_top_k = {}\n",
    "\n",
    "for uid in test_user_ids: \n",
    "# STEP 1: Content-Based \n",
    "    user_vector = create_user_preference_vector(travel_category, preferred_state, tfidf) \n",
    "    content_recs = get_content_based_recommendations(user_vector, tfidf_matrix, locations_df, top_n=50)\n",
    "    # STEP 2: Collaborative\n",
    "    similar_users = get_top_k_similar_users(interaction_matrix, uid, k=5)\n",
    "    collab_scores = predict_ratings_for_user(interaction_matrix, similar_users, uid)\n",
    "    \n",
    "    # STEP 3: Budget\n",
    "    filtered_content = apply_budget_filter(content_recs, location_costs, trip_budget)\n",
    "    \n",
    "    # STEP 4: Combine\n",
    "    final_recommendations = combine_scores(filtered_content, collab_scores, weight_content=0.6, weight_collab=0.4)\n",
    "    \n",
    "    top_recommended = final_recommendations.sort_values(\"hybrid_score\", ascending=False).head(10)\n",
    "    predicted_top_k[uid] = top_recommended[\"location_id\"].tolist()\n",
    "    \n",
    "    # Get actual visited locations from reviews\n",
    "    actual_locations = reviews_df[reviews_df[\"user_id\"] == uid][\"location_id\"].unique().tolist()\n",
    "    ground_truth[uid] = actual_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bea8fa0f-42ce-4310-91dd-2de0cb14f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision@K': 0.045, 'Recall@K': 0.225, 'NDCG@K': 0.19652406521325605}\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_topk(ground_truth, predicted_top_k, k=10)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1140b53-6934-43f4-927f-d6d319fb949f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
